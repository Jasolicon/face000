# 完整模型使用说明

## 概述

`FullMultiAngleFaceModel` 是一个端到端的模型，包含图像编码器和Transformer，可以直接处理原始图像输入。

## 模型架构

```
多角度图像 [B, 3, 224, 224]
    ↓
图像编码器 (ResNet50 或 DINOv2)
    ↓
特征向量 [B, feature_dim]
    ↓
特征投影 [B, d_model]
    ↓
Transformer (角度条件)
    ↓
残差 + 输入特征
    ↓
输出特征 [B, d_model]
```

## 主要组件

### 1. ImageEncoder（图像编码器）

支持两种编码器：

- **ResNet50**：
  - 使用预训练的ResNet50作为backbone
  - 输出2048维特征，投影到目标维度
  - 适合快速训练和推理

- **DINOv2**：
  - 使用DINOv2 ViT模型
  - 支持多种模型大小（vits14, vitb14, vitl14, vitg14）
  - 特征质量更高，但参数量更大

### 2. FullMultiAngleFaceModel（完整模型）

包含：
- 图像编码器（多角度图像）
- 正面图像编码器（共享权重）
- Transformer（特征转换）
- 输出投影层

## 使用方法

### 基本使用

```python
import torch
from train_transformer.models_full import FullMultiAngleFaceModel

# 创建模型（ResNet50版本）
model = FullMultiAngleFaceModel(
    encoder_type='resnet50',  # 或 'dinov2'
    feature_dim=768,
    d_model=768,
    nhead=8,
    num_layers=4,
    dim_feedforward=2048,
    dropout=0.1,
    freeze_encoder=False  # 是否冻结编码器
).to(device)

# 输入数据
multi_angle_images = torch.randn(batch_size, 3, 224, 224)  # 多角度图像（已归一化）
face_images = torch.randn(batch_size, 3, 224, 224)  # 正面图像（已归一化）
angles = torch.randn(batch_size, 5)  # 球面角

# 前向传播
predicted_features, target_features = model(
    multi_angle_images, face_images, angles
)
```

### 预测模式（只需要多角度图像）

```python
# 单张图像预测
multi_angle_image = torch.randn(3, 224, 224)  # [C, H, W]
angles = torch.randn(5)  # [5]

predicted_features = model.predict(multi_angle_image, angles)
# 返回: [d_model]
```

### 使用DINOv2编码器

```python
model = FullMultiAngleFaceModel(
    encoder_type='dinov2',
    feature_dim=768,
    d_model=768,
    dinov2_model_name='dinov2_vitb14',  # 或 'dinov2_vits14', 'dinov2_vitl14', 'dinov2_vitg14'
    freeze_encoder=False
).to(device)
```

## 图像预处理

模型需要输入已归一化的图像张量：

### ResNet50预处理

```python
from torchvision import transforms

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])
```

### DINOv2预处理

DINOv2使用自己的预处理，模型内部已处理。

## 训练建议

### 1. 冻结编码器（迁移学习）

```python
model = FullMultiAngleFaceModel(
    encoder_type='resnet50',
    freeze_encoder=True  # 冻结编码器，只训练Transformer
)
```

### 2. 端到端训练

```python
model = FullMultiAngleFaceModel(
    encoder_type='resnet50',
    freeze_encoder=False  # 同时训练编码器和Transformer
)
```

### 3. 学习率设置

- 如果冻结编码器：使用较大的学习率（如 `2e-4`）
- 如果端到端训练：使用较小的学习率（如 `1e-4`），或使用不同的学习率

```python
# 不同学习率示例
optimizer = torch.optim.AdamW([
    {'params': model.image_encoder.parameters(), 'lr': 1e-5},  # 编码器使用小学习率
    {'params': model.transformer.parameters(), 'lr': 2e-4}    # Transformer使用大学习率
], weight_decay=1e-4)
```

## 参数量对比

| 编码器类型 | 参数量（约） | 特征维度 | 速度 |
|-----------|------------|---------|------|
| ResNet50 | ~25M | 768 | 快 |
| DINOv2 ViT-S | ~22M | 384 | 中等 |
| DINOv2 ViT-B | ~86M | 768 | 慢 |
| DINOv2 ViT-L | ~300M | 1024 | 很慢 |

## 优势

1. **端到端训练**：可以直接从原始图像训练，无需预提取特征
2. **灵活性**：支持ResNet50和DINOv2两种编码器
3. **可扩展性**：可以轻松添加其他编码器（如EfficientNet、ConvNeXt等）
4. **迁移学习**：支持冻结编码器，只训练Transformer部分

## 注意事项

1. **显存占用**：端到端训练需要更多显存，建议使用混合精度训练（FP16）
2. **训练时间**：端到端训练比使用预提取特征慢，但可能获得更好的性能
3. **数据加载**：需要加载原始图像，数据加载速度可能成为瓶颈
4. **DINOv2模型**：首次使用需要下载模型，建议提前下载

## 与预提取特征模型的对比

| 特性 | 预提取特征模型 | 完整模型 |
|------|--------------|---------|
| 输入 | 特征向量 | 原始图像 |
| 训练速度 | 快 | 慢 |
| 显存占用 | 低 | 高 |
| 灵活性 | 低 | 高 |
| 端到端优化 | 否 | 是 |
| 适用场景 | 快速实验 | 最终部署 |

## 示例代码

完整训练示例请参考 `train_full_model.py`（如果存在）。

