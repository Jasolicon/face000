# TransformerFaceDataset 数据读取说明

## 概述

`TransformerFaceDataset` 用于训练 Transformer 模型，将不同角度的人脸图片转换为正面图特征。

## 数据流程

### 1. 初始化阶段 (`__init__`)

```python
dataset = TransformerFaceDataset(
    features_224_dir='features_224',      # 特征库目录
    video_dir='train/datas/video',         # 视频帧目录
    face_dir='train/datas/face',           # 正面图目录
    valid_images_file=None,                # 有效图片列表（可选）
    use_cpu=False,                         # 是否使用CPU
    cache_features=True                    # 是否缓存特征
)
```

#### 步骤 1.1: 初始化工具
```python
# 初始化 DINOv2 特征提取器
self.feature_extractor = DINOv2FeatureExtractor(...)

# 初始化 InsightFace 检测器（用于关键点检测）
self.detector = get_insightface_detector(...)
```

#### 步骤 1.2: 加载特征库
```python
# 从 features_224 目录加载预提取的特征
self.feature_manager = FeatureManager(storage_dir=features_224_dir)
self.features_224, self.metadata_224 = self.feature_manager.get_all_features()
# features_224: numpy数组，形状 [N, 768]（N个特征，每个768维）
# metadata_224: 元数据列表，包含 person_name, image_path 等信息
```

#### 步骤 1.3: 构建样本列表

**方式 A: 从目录扫描构建** (`_build_samples()`)

```python
# 1. 扫描正面图目录，获取所有人名
face_names = {'柴懿珈', '袁润东', ...}

# 2. 从 features_224 元数据中获取人名
features_224_names = {
    '柴懿珈': [
        {'index': 0, 'image_path': '...', 'metadata': {...}},
        {'index': 1, 'image_path': '...', 'metadata': {...}}
    ],
    '袁润东': [...]
}

# 3. 找到共有的人名
common_names = face_names ∩ features_224_names.keys()

# 4. 为每个人构建样本
for person_name in common_names:
    # 获取正面图路径
    face_image_path = face_dir / f"{person_name}.jpg"
    
    # 在 features_224 中查找匹配的特征
    feature_224_index = find_matching_feature(...)
    
    # 获取该人的所有视频帧
    video_images = sorted(video_dir / person_name / "*.jpg")
    
    # 为每个视频帧创建一个样本
    for video_image_path in video_images:
        samples.append({
            'video_image_path': str(video_image_path),  # 输入：角度图
            'face_image_path': str(face_image_path),    # 目标：正面图
            'person_name': person_name,
            'feature_224_index': feature_224_index      # features_224中的索引
        })
```

**方式 B: 从文件加载** (`_build_samples_from_file()`)

如果提供了 `valid_images_file`（JSON格式），则从文件加载：

```json
{
    "柴懿珈": {
        "face_image_path": "train/datas/face/柴懿珈.jpg",
        "video_images": [
            "train/datas/video/柴懿珈/frame_001.jpg",
            "train/datas/video/柴懿珈/frame_002.jpg",
            ...
        ]
    },
    "袁润东": {...}
}
```

### 2. 数据获取阶段 (`__getitem__`)

当 DataLoader 请求一个样本时，会调用 `__getitem__(idx)`：

```python
def __getitem__(self, idx: int):
    sample_info = self.samples[idx]  # 获取样本信息
    
    # 步骤 1: 提取输入特征（从视频帧图片）
    input_features = self._extract_dinov2_features(
        sample_info['video_image_path']  # 例如: "train/datas/video/柴懿珈/frame_001.jpg"
    )
    # 返回: numpy数组 [768] 或 [384]，取决于DINOv2模型
    
    # 步骤 2: 计算球面角（位置编码）
    angles, _ = self._calculate_spherical_angles(
        sample_info['video_image_path'],  # 视频帧
        sample_info['face_image_path']    # 正面图
    )
    # 返回: numpy数组 [5]，5个关键点的球面角
    
    # 步骤 3: 获取目标特征（从 features_224 或实时提取）
    if sample_info['feature_224_index'] is not None:
        # 从预加载的特征库中获取
        target_features = self.features_224[sample_info['feature_224_index']]
    else:
        # 实时从正面图提取
        target_features = self._extract_dinov2_features(
            sample_info['face_image_path']
        )
    # 返回: numpy数组 [768]
    
    # 步骤 4: 计算残差（训练目标）
    residual = target_features - input_features
    # 残差 = 正面特征 - 角度特征
    
    # 步骤 5: 转换为 torch.Tensor
    return {
        'input_features': torch.FloatTensor(input_features),      # [768] 输入特征
        'position_encoding': torch.FloatTensor(angles),           # [5] 位置编码
        'target_features': torch.FloatTensor(target_features),     # [768] 目标特征
        'target_residual': torch.FloatTensor(residual),           # [768] 残差
        'person_name': sample_info['person_name']                 # 字符串
    }
```

### 3. 特征提取详解

#### 3.1 DINOv2 特征提取 (`_extract_dinov2_features`)

```python
def _extract_dinov2_features(self, image_path: str):
    # 检查缓存
    if image_path in self.feature_cache:
        return self.feature_cache[image_path]
    
    # 使用 DINOv2 提取特征
    features = self.feature_extractor.extract_features(image_path)
    # 返回: numpy数组 [768] 或 [384]
    
    # 缓存特征（如果启用）
    if self.cache_features:
        self.feature_cache[image_path] = features
    
    return features
```

**特征提取流程**：
1. 加载图片
2. 预处理（resize, normalize）
3. 通过 DINOv2 模型提取特征
4. 返回特征向量

#### 3.2 球面角计算 (`_calculate_spherical_angles`)

```python
def _calculate_spherical_angles(self, video_image_path, face_image_path):
    # 步骤 1: 检测关键点
    face_landmarks, face_box = get_insightface_landmarks(
        self.detector, face_image_path
    )
    video_landmarks, video_box = get_insightface_landmarks(
        self.detector, video_image_path
    )
    
    # 步骤 2: 转换为3D坐标
    face_landmarks_3d = landmarks_to_3d(face_landmarks, face_box, ...)
    video_landmarks_3d = landmarks_to_3d(video_landmarks, video_box, ...)
    
    # 步骤 3: 计算球面角
    angles, avg_angle = calculate_spherical_angle(
        face_landmarks_3d, video_landmarks_3d, ...
    )
    # 返回: numpy数组 [5]，5个关键点的角度
    
    return angles, avg_angle
```

**球面角含义**：
- 5个关键点：左眼、右眼、鼻尖、左嘴角、右嘴角
- 每个角度表示该关键点相对于正面图的旋转角度
- 用于位置编码，告诉模型输入图片的角度信息

### 4. DataLoader 使用

```python
# 创建 DataLoader
dataloader = DataLoader(
    dataset,
    batch_size=32,
    shuffle=True,
    num_workers=0,
    collate_fn=collate_fn  # 自定义批次处理
)

# 批次数据格式
for batch in dataloader:
    batch = {
        'input_features': torch.Tensor,      # [B, 768] 输入特征
        'position_encoding': torch.Tensor,   # [B, 5] 位置编码
        'target_features': torch.Tensor,     # [B, 768] 目标特征
        'target_residual': torch.Tensor,     # [B, 768] 残差
        'person_names': List[str]            # [B] 人名列表
    }
```

## 数据目录结构

```
train/
└── datas/
    ├── face/                    # 正面图目录
    │   ├── 柴懿珈.jpg
    │   └── 袁润东.jpg
    └── video/                   # 视频帧目录
        ├── 柴懿珈/
        │   ├── frame_001.jpg
        │   ├── frame_002.jpg
        │   └── ...
        └── 袁润东/
            ├── frame_001.jpg
            └── ...

features_224/                    # 特征库目录
├── features.npy                 # 特征数组 [N, 768]
└── metadata.json                # 元数据（包含 person_name, image_path）
```

## 数据流向图

```
初始化阶段:
┌─────────────────┐
│ 扫描目录/文件   │
│ 构建样本列表     │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ 加载特征库       │
│ features_224     │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ 初始化工具       │
│ - DINOv2         │
│ - InsightFace    │
└─────────────────┘

数据获取阶段 (__getitem__):
┌─────────────────┐
│ 视频帧图片       │
│ (角度图)         │
└────────┬────────┘
         │
         ▼
┌─────────────────┐      ┌─────────────────┐
│ DINOv2提取特征  │      │ 计算球面角       │
│ [768维]         │      │ [5维]            │
└────────┬────────┘      └────────┬────────┘
         │                        │
         └────────┬───────────────┘
                  ▼
         ┌─────────────────┐
         │ input_features  │
         │ position_encoding│
         └────────┬────────┘
                  │
                  ▼
         ┌─────────────────┐
         │ 正面图特征       │
         │ (从features_224) │
         └────────┬────────┘
                  │
                  ▼
         ┌─────────────────┐
         │ 计算残差         │
         │ residual =       │
         │   target - input │
         └────────┬────────┘
                  │
                  ▼
         ┌─────────────────┐
         │ 返回样本         │
         │ (torch.Tensor)   │
         └─────────────────┘
```

## 关键特性

### 1. 特征缓存
- 如果 `cache_features=True`，提取的特征会被缓存
- 避免重复提取相同图片的特征
- 加速训练过程

### 2. 特征库匹配
- 优先从 `features_224` 加载目标特征（更快）
- 如果找不到匹配，实时提取（较慢）
- 支持路径匹配和文件名匹配

### 3. 球面角计算
- 使用 InsightFace 检测关键点
- 转换为3D坐标
- 计算相对于正面图的角度
- 作为位置编码输入 Transformer

### 4. 残差学习
- 训练目标不是直接预测正面特征
- 而是预测**残差**（正面特征 - 角度特征）
- 这样模型只需要学习角度差异，更容易训练

## 使用示例

```python
# 创建数据集
dataset = TransformerFaceDataset(
    features_224_dir='features_224',
    video_dir='train/datas/video',
    face_dir='train/datas/face',
    cache_features=True
)

# 获取单个样本
sample = dataset[0]
print(f"输入特征: {sample['input_features'].shape}")      # [768]
print(f"位置编码: {sample['position_encoding'].shape}")   # [5]
print(f"目标特征: {sample['target_features'].shape}")      # [768]
print(f"残差: {sample['target_residual'].shape}")          # [768]

# 创建 DataLoader
from train_transformer.dataset import create_dataloader
dataloader = create_dataloader(dataset, batch_size=32)

# 训练循环
for batch in dataloader:
    input_features = batch['input_features']        # [32, 768]
    position_encoding = batch['position_encoding'] # [32, 5]
    target_residual = batch['target_residual']     # [32, 768]
    
    # 模型预测
    predicted_residual = model(input_features, position_encoding)
    
    # 计算损失
    loss = criterion(predicted_residual, target_residual)
```

## 注意事项

1. **特征维度一致性**：
   - `input_features` 和 `target_features` 的维度必须一致
   - 如果使用小模型（384维），需要调整模型输入维度

2. **特征库匹配**：
   - 确保 `features_224` 中包含对应的人名
   - 优先使用路径匹配，失败则使用第一个特征

3. **球面角计算**：
   - 如果无法检测关键点，返回全零角度
   - 使用 `valid_images_file` 可以预先筛选有效图片

4. **内存使用**：
   - `features_224` 会全部加载到内存
   - 如果特征库很大，注意内存占用

