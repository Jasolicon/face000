# 多姿态人脸生成使用指南

## 概述

本功能使用 **Stable Diffusion + ControlNet + OpenPose** 来生成同一人的多姿态人脸图像。通过提取正面人脸的姿态关键点，修改为目标姿态，然后使用 ControlNet 条件生成对应姿态的人脸图像。

## 安装依赖

### 必需依赖

```bash
pip install diffusers controlnet-aux>=0.0.10 accelerate
```

### 可选依赖（优化显存）

```bash
pip install xformers
```

### 完整安装

```bash
pip install -r requirements.txt
```

## 功能特点

1. **自动人脸检测**：使用 MTCNN 自动检测和裁剪人脸
2. **姿态关键点提取**：使用 OpenPose 提取 17 个骨骼点 + 68 个面部关键点
3. **姿态修改**：支持多种目标姿态（侧脸、低头、抬头、左转、右转）
4. **条件生成**：使用 ControlNet（OpenPose 条件）生成高质量人脸图像

## 使用方法

### 方法 1: 命令行使用

```bash
python generate_multi_pose_faces.py --input path/to/face.jpg --output-dir output
```

### 方法 2: Python 代码使用

```python
from generate_multi_pose_faces import MultiPoseFaceGenerator

# 初始化生成器
generator = MultiPoseFaceGenerator()

# 生成多姿态人脸
output_paths = generator.generate_multi_pose_faces(
    input_image_path="path/to/face.jpg",
    output_dir="generated_poses",
    poses=["side", "down", "up", "left", "right"]
)
```

## 详细参数说明

### 初始化参数

```python
generator = MultiPoseFaceGenerator(
    model_id="runwayml/stable-diffusion-v1-5",  # SD 模型
    controlnet_model_id="lllyasviel/sd-controlnet-openpose",  # ControlNet 模型
    device="cuda",  # 或 "cpu"
    use_fp16=True  # 使用半精度以节省显存
)
```

### 生成参数

```python
output_paths = generator.generate_multi_pose_faces(
    input_image_path="face.jpg",  # 输入图像路径
    output_dir="output",  # 输出目录
    poses=["side", "down", "up"],  # 目标姿态列表
    angles={  # 每个姿态的旋转角度（可选）
        "side": 45.0,
        "down": 0.0,
        "up": 0.0
    },
    prompt="a high quality portrait photo of a person",  # 生成提示词
    num_inference_steps=20  # 推理步数（越多质量越好但越慢）
)
```

## 支持的姿态

| 姿态 | 说明 | 默认角度 |
|------|------|----------|
| `side` | 侧脸 | 45° |
| `down` | 低头 | 0°（向下移动） |
| `up` | 抬头 | 0°（向上移动） |
| `left` | 向左转 | 30° |
| `right` | 向右转 | -30° |

## 命令行参数

```bash
python generate_multi_pose_faces.py \
    --input face.jpg \                    # 输入图像（必需）
    --output-dir output \                 # 输出目录（默认: generated_poses）
    --poses side down up left right \     # 目标姿态（默认: 全部）
    --prompt "a high quality portrait" \ # 生成提示词
    --steps 20 \                          # 推理步数（默认: 20）
    --device cuda                         # 计算设备（默认: 自动选择）
```

## 工作流程

### 1. 提取正面人脸的姿态关键点

```python
face_image, pose_image = generator.extract_face_pose("face.jpg")
```

- 使用 MTCNN 检测人脸
- 裁剪人脸区域
- 使用 OpenPose 提取关键点（17 个骨骼点 + 68 个面部关键点）

### 2. 修改姿态关键点

```python
modified_pose = generator.modify_pose_keypoints(
    pose_image,
    target_pose="side",
    angle=45.0
)
```

- 根据目标姿态旋转或移动关键点
- 支持侧脸、低头、抬头等姿态

### 3. 条件生成

```python
generated_image = generator.generate_face_with_pose(
    face_image,
    modified_pose,
    prompt="a high quality portrait photo",
    num_inference_steps=20
)
```

- 使用 ControlNet（OpenPose 条件）
- 以原始人脸作为参考
- 生成对应姿态的人脸图像

## 输出文件

生成的文件保存在输出目录中：

```
output/
├── 00_original_face.jpg      # 原始人脸
├── 00_original_pose.jpg      # 原始姿态关键点
├── 01_side_face.jpg          # 侧脸
├── 02_down_face.jpg          # 低头
├── 03_up_face.jpg            # 抬头
├── 04_left_face.jpg          # 左转
└── 05_right_face.jpg         # 右转
```

## 提示词建议

### 基础提示词

```
"a high quality portrait photo of a person, detailed face, realistic, professional photography"
```

### 增强提示词

```
"a high quality portrait photo of a person, detailed face, realistic, professional photography, 
sharp focus, studio lighting, 8k, uhd, dslr, soft lighting, high quality, film grain"
```

### 负面提示词（默认）

```
"blurry, low quality, distorted, deformed, ugly, bad anatomy, bad proportions"
```

## 性能优化

### 1. 使用 FP16（半精度）

```python
generator = MultiPoseFaceGenerator(use_fp16=True)
```

- 减少显存占用约 50%
- 速度提升约 20-30%

### 2. 调整推理步数

```python
# 快速模式（质量略低）
num_inference_steps = 10

# 平衡模式（推荐）
num_inference_steps = 20

# 高质量模式（较慢）
num_inference_steps = 50
```

### 3. 使用 xformers（如果可用）

```bash
pip install xformers
```

- 自动优化注意力机制
- 减少显存占用和加速推理

### 4. CPU 模式优化

如果使用 CPU，会自动启用内存优化：

```python
# 自动启用 attention slicing
generator = MultiPoseFaceGenerator(device="cpu")
```

## 常见问题

### Q1: 显存不足

**解决方案**：
1. 使用 FP16：`use_fp16=True`
2. 安装 xformers：`pip install xformers`
3. 减少推理步数：`num_inference_steps=10`
4. 使用 CPU（较慢）：`device="cpu"`

### Q2: 生成的人脸不像原图

**解决方案**：
1. 增加推理步数：`num_inference_steps=30-50`
2. 调整控制强度：`controlnet_conditioning_scale=0.8-1.0`
3. 优化提示词，添加更多细节描述

### Q3: 姿态不准确

**解决方案**：
1. 调整角度参数：`angles={"side": 60.0}`
2. 手动修改关键点位置
3. 使用更精确的姿态检测模型

### Q4: 模型下载失败

**解决方案**：
1. 使用镜像源：
   ```bash
   export HF_ENDPOINT=https://hf-mirror.com
   ```
2. 手动下载模型到本地
3. 使用本地模型路径

## 高级用法

### 自定义姿态关键点

```python
# 手动修改关键点
pose_array = np.array(pose_image)
# 修改关键点位置...
modified_pose = Image.fromarray(pose_array)
```

### 批量处理

```python
import glob

image_files = glob.glob("faces/*.jpg")
for img_file in image_files:
    generator.generate_multi_pose_faces(
        input_image_path=img_file,
        output_dir=f"output/{Path(img_file).stem}"
    )
```

### 集成到现有系统

```python
from face_detector import FaceDetector
from generate_multi_pose_faces import MultiPoseFaceGenerator

# 检测人脸
detector = FaceDetector()
faces, boxes, probs = detector.detect_faces("image.jpg")

# 生成多姿态
generator = MultiPoseFaceGenerator()
for i, face in enumerate(faces):
    face.save(f"temp_face_{i}.jpg")
    generator.generate_multi_pose_faces(
        input_image_path=f"temp_face_{i}.jpg",
        output_dir=f"poses/person_{i}"
    )
```

## 技术细节

### 模型架构

- **Stable Diffusion v1.5**: 基础生成模型
- **ControlNet OpenPose**: 姿态条件控制
- **OpenPose**: 关键点检测

### 关键点格式

OpenPose 检测的关键点包括：
- **17 个身体骨骼点**：头部、肩膀、手臂等
- **68 个面部关键点**：眼睛、鼻子、嘴巴等

### 生成流程

1. 输入图像 → MTCNN 人脸检测
2. 裁剪人脸 → OpenPose 关键点检测
3. 修改关键点 → 目标姿态
4. ControlNet 条件生成 → 新姿态人脸

## 注意事项

1. **首次运行**：需要下载模型（约 4-5 GB），请确保网络畅通
2. **显存要求**：建议至少 8GB 显存（使用 FP16）
3. **生成时间**：每张图像约 10-30 秒（取决于硬件和步数）
4. **质量平衡**：推理步数越多质量越好，但速度越慢

## 示例

### 完整示例

```python
from generate_multi_pose_faces import MultiPoseFaceGenerator

# 初始化
generator = MultiPoseFaceGenerator(
    device="cuda",
    use_fp16=True
)

# 生成多姿态人脸
output_paths = generator.generate_multi_pose_faces(
    input_image_path="test_face.jpg",
    output_dir="generated_poses",
    poses=["side", "down", "up"],
    prompt="a high quality portrait photo of a person, detailed face, realistic",
    num_inference_steps=25
)

print("生成完成！")
for pose, path in output_paths.items():
    print(f"{pose}: {path}")
```

## 参考资源

- [Stable Diffusion](https://github.com/Stability-AI/stablediffusion)
- [ControlNet](https://github.com/lllyasviel/ControlNet)
- [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose)
- [Diffusers 文档](https://huggingface.co/docs/diffusers)

