# SENetä¸‰å…ƒç»„ç½‘ç»œä½¿ç”¨è¯´æ˜

## ğŸ“‹ æ¦‚è¿°

`SENetTripletNetwork`æ˜¯åŸºäºSqueeze-and-Excitationæœºåˆ¶çš„ä¸‰å…ƒç»„ç½‘ç»œï¼Œé€šè¿‡åŒåˆ†æ”¯æ¶æ„æ˜ç¡®åˆ†ç¦»èº«ä»½ç‰¹å¾å’Œå§¿æ€ç‰¹å¾ã€‚

## ğŸ—ï¸ æ¶æ„ç‰¹ç‚¹

### 1. åŒåˆ†æ”¯SENet

- **èº«ä»½åˆ†æ”¯**ï¼šä¿æŠ¤é«˜ç›¸ä¼¼ç»´åº¦ï¼ˆå¦‚ç»´åº¦60, 312, 459ç­‰ï¼‰
- **å§¿æ€åˆ†æ”¯**ï¼šå­¦ä¹ ä½ç›¸ä¼¼ç»´åº¦è½¬æ¢ï¼ˆå¦‚ç»´åº¦229, 334, 437ç­‰ï¼‰
- **èåˆæœºåˆ¶**ï¼šå¯å­¦ä¹ çš„åŠ æƒæ±‚å’Œï¼ˆé»˜è®¤Î±=0.7ï¼‰

### 2. æ ¸å¿ƒç»„ä»¶

- `SEBlock`: Squeeze-and-Excitationå—ï¼Œå­¦ä¹ é€šé“æƒé‡
- `DualBranchSENet`: åŒåˆ†æ”¯æ¶æ„ï¼Œåˆ†ç¦»èº«ä»½å’Œå§¿æ€ç‰¹å¾
- `SENetTripletNetwork`: å®Œæ•´çš„ä¸‰å…ƒç»„ç½‘ç»œ

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```python
from train_transformer3D.triplet import SENetTripletNetwork
import torch

# åˆ›å»ºæ¨¡å‹
model = SENetTripletNetwork(
    image_dim=512,          # å›¾åƒç‰¹å¾ç»´åº¦
    pose_dim=3,            # å§¿åŠ¿ç»´åº¦
    hidden_dim=1024,       # éšè—å±‚ç»´åº¦
    num_layers=3,         # å…¨è¿æ¥å±‚æ•°é‡
    se_reduction=16,       # SE Blockå‹ç¼©æ¯”ä¾‹
    fusion_alpha=0.7,      # èº«ä»½åˆ†æ”¯åˆå§‹æƒé‡
    learnable_fusion=True  # æ˜¯å¦å­¦ä¹ èåˆæƒé‡
)

# å‰å‘ä¼ æ’­
src = torch.randn(4, 512)      # å›¾åƒç‰¹å¾
pose = torch.randn(4, 3)       # å§¿åŠ¿ç‰¹å¾

front_features, identity_features, front_pose = model(
    src=src,
    pose=pose,
    return_identity_features=True,
    return_front_pose=True
)

print(f"æ­£é¢ç‰¹å¾: {front_features.shape}")      # [4, 512]
print(f"èº«ä»½ç‰¹å¾: {identity_features.shape}")   # [4, 512]
print(f"æ­£é¢å§¿åŠ¿: {front_pose.shape}")          # [4, 3]
```

### è·å–åˆ†æ”¯è¾“å‡ºï¼ˆç”¨äºåˆ†æï¼‰

```python
# è¿”å›åˆ†æ”¯è¾“å‡º
front_features, identity_features, front_pose, identity_branch, pose_branch = model(
    src=src,
    pose=pose,
    return_identity_features=True,
    return_front_pose=True,
    return_branches=True  # è¿”å›åˆ†æ”¯è¾“å‡º
)

print(f"èº«ä»½åˆ†æ”¯: {identity_branch.shape}")  # [4, 512]
print(f"å§¿æ€åˆ†æ”¯: {pose_branch.shape}")      # [4, 512]

# è·å–å½“å‰èåˆæƒé‡
fusion_alpha = model.get_fusion_alpha()
print(f"èåˆæƒé‡ (Î±): {fusion_alpha:.4f}")
```

## ğŸ”§ è®­ç»ƒé›†æˆ

### ä¸ç°æœ‰è®­ç»ƒè„šæœ¬é›†æˆ

å¯ä»¥ä¿®æ”¹`train_simple_triplet.py`æ¥ä½¿ç”¨SENetæ¨¡å‹ï¼š

```python
# åœ¨train_simple_triplet.pyä¸­
from train_transformer3D.triplet import SENetTripletNetwork

# åˆ›å»ºæ¨¡å‹
model = SENetTripletNetwork(
    image_dim=512,
    pose_dim=3,
    hidden_dim=1024,
    num_layers=3,
    se_reduction=16,
    fusion_alpha=0.7,
    learnable_fusion=True
)
```

### æ·»åŠ èº«ä»½ä¿æŠ¤æŸå¤±

```python
# åœ¨è®­ç»ƒå¾ªç¯ä¸­
# å®šä¹‰é«˜ç›¸ä¼¼ç»´åº¦ï¼ˆä»ç‰¹å¾åˆ†ææŠ¥å‘Šä¸­è·å–ï¼‰
identity_dims = [60, 312, 459, 217, 115, 74, 350, 113, 305, 149]

# è·å–åˆ†æ”¯è¾“å‡º
front_features, identity_features, front_pose, identity_branch, pose_branch = model(
    src=batch['src'],
    pose=batch['pose'],
    return_identity_features=True,
    return_front_pose=True,
    return_branches=True
)

# è®¡ç®—èº«ä»½ä¿æŠ¤æŸå¤±ï¼ˆä¿æŠ¤é«˜ç›¸ä¼¼ç»´åº¦ï¼‰
identity_preserve_loss = F.mse_loss(
    front_features[:, identity_dims],
    batch['src'][:, identity_dims]
)

# ä¸‰å…ƒç»„æŸå¤±
triplet_loss = criterion(identity_features, labels, batch['pose'], batch['src'])

# æ€»æŸå¤±
total_loss = triplet_loss + 0.3 * identity_preserve_loss
```

## ğŸ“Š è¶…å‚æ•°å»ºè®®

### åŸºç¡€é…ç½®

```python
model = SENetTripletNetwork(
    image_dim=512,
    pose_dim=3,
    hidden_dim=1024,
    num_layers=3,
    dropout=0.1,
    activation='relu',
    se_reduction=16,      # æ¨èå€¼ï¼š8-32
    fusion_alpha=0.7,     # æ¨èå€¼ï¼š0.6-0.8
    learnable_fusion=True  # æ¨èï¼šTrue
)
```

### é«˜çº§é…ç½®

```python
# æ›´æ·±çš„ç½‘ç»œ
model = SENetTripletNetwork(
    image_dim=512,
    pose_dim=3,
    hidden_dim=2048,      # æ›´å¤§çš„éšè—å±‚
    num_layers=5,         # æ›´æ·±çš„ç½‘ç»œ
    se_reduction=8,        # æ›´å°çš„å‹ç¼©æ¯”ä¾‹ï¼ˆæ›´å¤šå‚æ•°ï¼‰
    fusion_alpha=0.75,     # æ›´é«˜çš„èº«ä»½æƒé‡
    learnable_fusion=True
)
```

## ğŸ¯ é¢„æœŸæ•ˆæœ

### ç†è®ºä¼˜åŠ¿

1. **èº«ä»½ä¿æŠ¤**ï¼šSENetå¯ä»¥å­¦ä¹ åˆ°é«˜ç›¸ä¼¼ç»´åº¦åº”è¯¥è¢«ä¿ç•™
2. **å§¿æ€å­¦ä¹ **ï¼šSENetå¯ä»¥å­¦ä¹ åˆ°ä½ç›¸ä¼¼ç»´åº¦åº”è¯¥è¢«è½¬æ¢
3. **è‡ªé€‚åº”å¹³è¡¡**ï¼šèåˆæƒé‡å¯ä»¥é€šè¿‡è®­ç»ƒè‡ªåŠ¨å­¦ä¹ 

### é¢„æœŸæŒ‡æ ‡æ”¹è¿›

| æŒ‡æ ‡ | å½“å‰å€¼ | é¢„æœŸå€¼ | æ”¹è¿› |
|------|--------|--------|------|
| æ¨¡å‹è¾“å‡º vs åŸå§‹æ­£é¢ | 0.146 | >0.5 | +242% |
| æ¨¡å‹è¾“å‡º vs åŸå§‹ä¾§é¢ | 0.162 | >0.3 | +85% |
| èº«ä»½ç»´åº¦ä¿æŠ¤ç‡ | - | >0.8 | æ–°å¢ |

## ğŸ” ç›‘æ§å’Œè°ƒè¯•

### ç›‘æ§èåˆæƒé‡

```python
# åœ¨è®­ç»ƒå¾ªç¯ä¸­
if epoch % 10 == 0:
    fusion_alpha = model.get_fusion_alpha()
    print(f"Epoch {epoch}: èåˆæƒé‡ Î± = {fusion_alpha:.4f}")
    print(f"  èº«ä»½åˆ†æ”¯æƒé‡: {fusion_alpha:.4f}")
    print(f"  å§¿æ€åˆ†æ”¯æƒé‡: {1 - fusion_alpha:.4f}")
```

### å¯è§†åŒ–åˆ†æ”¯è¾“å‡º

```python
# è·å–åˆ†æ”¯è¾“å‡º
_, _, _, identity_branch, pose_branch = model(
    src=src,
    pose=pose,
    return_branches=True
)

# åˆ†æåˆ†æ”¯ç‰¹å¾
# identity_branchåº”è¯¥ä¸åŸå§‹ç‰¹å¾ç›¸ä¼¼ï¼ˆé«˜ç›¸ä¼¼ç»´åº¦ï¼‰
# pose_branchåº”è¯¥å­¦ä¹ è½¬æ¢ï¼ˆä½ç›¸ä¼¼ç»´åº¦ï¼‰
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. è®­ç»ƒç¨³å®šæ€§

- å»ºè®®ä½¿ç”¨è¾ƒå°çš„åˆå§‹å­¦ä¹ ç‡ï¼ˆå¦‚1e-4ï¼‰
- å¯ä»¥ä½¿ç”¨æ¸è¿›å¼è®­ç»ƒï¼ˆå…ˆè®­ç»ƒå•åˆ†æ”¯ï¼Œå†è®­ç»ƒåŒåˆ†æ”¯ï¼‰
- æ·»åŠ æ¢¯åº¦è£å‰ª

### 2. è¿‡æ‹Ÿåˆé£é™©

- ä½¿ç”¨Dropoutï¼ˆé»˜è®¤0.1ï¼‰
- ä½¿ç”¨æ•°æ®å¢å¼º
- ä½¿ç”¨æ­£åˆ™åŒ–

### 3. è®¡ç®—å¼€é”€

- SE Blockå¢åŠ çš„è®¡ç®—é‡å¾ˆå°ï¼ˆçº¦512*reduction_ratioå‚æ•°ï¼‰
- å¯ä»¥ä½¿ç”¨è¾ƒå°çš„reduction ratioï¼ˆå¦‚8æˆ–4ï¼‰æ¥å‡å°‘å‚æ•°

## ğŸ“ å®Œæ•´è®­ç»ƒç¤ºä¾‹

```python
import torch
import torch.nn as nn
import torch.optim as optim
from train_transformer3D.triplet import (
    SENetTripletNetwork,
    AngleAwareTripletLoss,
    create_triplet_train_val_test_dataloaders
)

# åˆ›å»ºæ¨¡å‹
model = SENetTripletNetwork(
    image_dim=512,
    pose_dim=3,
    hidden_dim=1024,
    num_layers=3,
    se_reduction=16,
    fusion_alpha=0.7,
    learnable_fusion=True
)

# åˆ›å»ºæŸå¤±å‡½æ•°
criterion = AngleAwareTripletLoss(
    margin=0.3,
    alpha=2.0,
    beta=1.0,
    angle_threshold=30.0
)

# åˆ›å»ºä¼˜åŒ–å™¨
optimizer = optim.AdamW(model.parameters(), lr=1e-4)

# åˆ›å»ºæ•°æ®åŠ è½½å™¨
train_loader, val_loader, test_loader = create_triplet_train_val_test_dataloaders(
    data_dir='path/to/data',
    batch_size=32,
    num_workers=4
)

# è®­ç»ƒå¾ªç¯
for epoch in range(100):
    model.train()
    for batch in train_loader:
        src = batch['src']
        pose = batch['pose']
        labels = batch['labels']  # éœ€è¦ä»person_nameè½¬æ¢
        
        # å‰å‘ä¼ æ’­
        front_features, identity_features, front_pose = model(
            src=src,
            pose=pose,
            return_identity_features=True,
            return_front_pose=True
        )
        
        # è®¡ç®—æŸå¤±
        triplet_loss = criterion(identity_features, labels, pose, src)
        
        # å¯é€‰ï¼šæ·»åŠ èº«ä»½ä¿æŠ¤æŸå¤±
        identity_dims = [60, 312, 459, 217, 115, 74, 350, 113, 305, 149]
        identity_preserve_loss = nn.functional.mse_loss(
            front_features[:, identity_dims],
            src[:, identity_dims]
        )
        
        total_loss = triplet_loss + 0.3 * identity_preserve_loss
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        total_loss.backward()
        optimizer.step()
    
    # éªŒè¯
    if epoch % 10 == 0:
        fusion_alpha = model.get_fusion_alpha()
        print(f"Epoch {epoch}: Loss = {total_loss.item():.4f}, Î± = {fusion_alpha:.4f}")
```

---

ç”Ÿæˆæ—¶é—´: 2024-12-16

