# TensorBoard "æ—¶é—´å€’æµ"ç°è±¡åˆ†æä¸è§£å†³æ–¹æ¡ˆ

## ğŸ” ç°è±¡æè¿°

åœ¨TensorBoardä¸­ï¼Œå³ä½¿æ¨ªåæ ‡æ˜¯è¿­ä»£æ¬¡æ•°ï¼ˆåº”è¯¥å•è°ƒé€’å¢ï¼‰ï¼ŒæŸäº›æ›²çº¿ä¼šå‡ºç°"æ—¶é—´å€’æµ"çš„è§†è§‰æ•ˆæœï¼š
- çº¿æ¡å‘åå»¶ä¼¸
- å¤šæ¡çº¿äº¤å‰é‡å 
- çœ‹èµ·æ¥åƒæ˜¯æ•°æ®åœ¨"å€’æµ"

## ğŸ“Š åŸå› åˆ†æ

### 1. **TensorBoardå¹³æ»‘ç®—æ³•ï¼ˆEMAï¼‰çš„æ»åæ•ˆåº”**

**ä¸»è¦åŸå› ï¼š** TensorBoardä½¿ç”¨**æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆEMAï¼‰**æ¥å¹³æ»‘æ›²çº¿

**EMAå…¬å¼ï¼š**
```
Smoothed[t] = alpha * Raw[t] + (1 - alpha) * Smoothed[t-1]
```

**æ»åæ•ˆåº”ï¼š**
- å½“åŸå§‹æ•°æ®å¿«é€Ÿå˜åŒ–æ—¶ï¼Œå¹³æ»‘æ›²çº¿ä¼š"æ»å"äºåŸå§‹æ•°æ®
- å¹³æ»‘æ›²çº¿æ€»æ˜¯"è·Ÿéš"åŸå§‹æ•°æ®ï¼Œè€Œä¸æ˜¯"é¢„æµ‹"
- è¿™å¯¼è‡´è§†è§‰ä¸Šçœ‹èµ·æ¥åƒæ˜¯"å€’æµ"

**ç¤ºä¾‹ï¼š**
```
åŸå§‹æ•°æ®: [10, 20, 15, 25, 18, 30]
å¹³æ»‘æ•°æ®: [10, 12, 13, 16, 17, 20]  # æ€»æ˜¯æ»åäºåŸå§‹æ•°æ®
```

### 2. **åŸå§‹æ•°æ®çš„é«˜æ–¹å·®**

**é—®é¢˜ï¼š** æŸäº›æŸå¤±ï¼ˆå¦‚`Loss_contrast`ã€`Loss_pose_consistency`ï¼‰æ–¹å·®å¾ˆå¤§

**è¡¨ç°ï¼š**
- åŸå§‹æ•°æ®ç‚¹æ³¢åŠ¨å‰§çƒˆ
- ç›¸é‚»è¿­ä»£çš„æŸå¤±å€¼å·®å¼‚å¾ˆå¤§
- ç»˜åˆ¶æ—¶äº§ç”Ÿå¤§é‡äº¤å‰çº¿æ¡

**ä»£ç ä¸­çš„è®°å½•ï¼š**
```python
# æ¯ä¸ªbatchéƒ½è®°å½•ä¸€æ¬¡
global_step = epoch * len(dataloader) + batch_idx
writer.add_scalar(f'Train/Loss_{key}', value.item(), global_step)
```

### 3. **æ•°æ®è®°å½•é¢‘ç‡è¿‡é«˜**

**é—®é¢˜ï¼š** æ¯ä¸ªbatchéƒ½è®°å½•ï¼Œå¯¼è‡´æ•°æ®ç‚¹éå¸¸å¯†é›†

**å½±å“ï¼š**
- æ•°æ®ç‚¹è¿‡å¤šï¼Œçº¿æ¡é‡å 
- é«˜æ–¹å·®æŸå¤±äº§ç”Ÿå¤§é‡äº¤å‰çº¿
- è§†è§‰ä¸Šå½¢æˆ"æ—¶é—´å€’æµ"æ•ˆæœ

### 4. **å¤šä¸ªè¿è¡Œæ•°æ®å åŠ ï¼ˆå·²ä¿®å¤ï¼‰**

**ä¹‹å‰çš„é—®é¢˜ï¼š** å¤šä¸ªè®­ç»ƒè¿è¡Œå†™å…¥åŒä¸€ä¸ªæ—¥å¿—ç›®å½•

**å·²ä¿®å¤ï¼š** ç°åœ¨ä½¿ç”¨æ—¶é—´æˆ³åˆ›å»ºç‹¬ç«‹ç›®å½•
```python
log_dir = base_log_dir / f"run_{timestamp}"
```

---

## âœ… è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šé™ä½è®°å½•é¢‘ç‡ï¼ˆæ¨èï¼‰

**é—®é¢˜ï¼š** æ¯ä¸ªbatchéƒ½è®°å½•ï¼Œæ•°æ®ç‚¹å¤ªå¯†é›†

**è§£å†³ï¼š** æ¯éš”Nä¸ªbatchè®°å½•ä¸€æ¬¡

```python
# ä¿®æ”¹ train_universal.py
# åœ¨ train_epoch å‡½æ•°ä¸­

# è®°å½•åˆ°TensorBoard
if writer is not None:
    global_step = epoch * len(dataloader) + batch_idx
    
    # æ”¹è¿›ï¼šæ¯éš”Nä¸ªbatchè®°å½•ä¸€æ¬¡ï¼Œå‡å°‘æ•°æ®ç‚¹å¯†åº¦
    log_interval = 10  # æ¯10ä¸ªbatchè®°å½•ä¸€æ¬¡
    if batch_idx % log_interval == 0 or batch_idx == len(dataloader) - 1:
        writer.add_scalar('Train/Loss', loss.item(), global_step)
        for key, value in losses.items():
            if isinstance(value, torch.Tensor):
                writer.add_scalar(f'Train/Loss_{key}', value.item(), global_step)
```

**æ•ˆæœï¼š**
- å‡å°‘æ•°æ®ç‚¹å¯†åº¦
- é™ä½è§†è§‰æ··ä¹±
- ä¿æŒè¶‹åŠ¿æ¸…æ™°

---

### æ–¹æ¡ˆ2ï¼šä½¿ç”¨ç§»åŠ¨å¹³å‡é¢„å¹³æ»‘

**é—®é¢˜ï¼š** TensorBoardçš„å¹³æ»‘å¯èƒ½ä¸å¤Ÿ

**è§£å†³ï¼š** åœ¨è®°å½•å‰å…ˆè¿›è¡Œç§»åŠ¨å¹³å‡

```python
# åœ¨è®­ç»ƒå¾ªç¯ä¸­ç»´æŠ¤ç§»åŠ¨å¹³å‡
class MovingAverage:
    def __init__(self, alpha=0.9):
        self.alpha = alpha
        self.value = None
    
    def update(self, new_value):
        if self.value is None:
            self.value = new_value
        else:
            self.value = self.alpha * new_value + (1 - self.alpha) * self.value
        return self.value

# åœ¨ train_epoch ä¸­
loss_moving_avg = {}
for key in ['Loss', 'Loss_id_similarity', 'Loss_contrast', ...]:
    loss_moving_avg[key] = MovingAverage(alpha=0.9)

# è®°å½•æ—¶ä½¿ç”¨ç§»åŠ¨å¹³å‡
if writer is not None:
    global_step = epoch * len(dataloader) + batch_idx
    smoothed_loss = loss_moving_avg['Loss'].update(loss.item())
    writer.add_scalar('Train/Loss', smoothed_loss, global_step)
```

---

### æ–¹æ¡ˆ3ï¼šè°ƒæ•´TensorBoardå¹³æ»‘å‚æ•°

**åœ¨TensorBoardç•Œé¢ä¸­ï¼š**
1. ç‚¹å‡»å³ä¸Šè§’çš„å¹³æ»‘æ»‘å—
2. å¢åŠ å¹³æ»‘åº¦ï¼ˆå‘å³æ‹–åŠ¨ï¼‰
3. å‡å°‘åŸå§‹æ•°æ®ç‚¹çš„æ˜¾ç¤º

**æˆ–è€…ä½¿ç”¨å‘½ä»¤è¡Œï¼š**
```bash
tensorboard --smoothing=0.9 --logdir=logs
```

---

### æ–¹æ¡ˆ4ï¼šåˆ†ç¦»é«˜æ–¹å·®æŸå¤±

**é—®é¢˜ï¼š** æŸäº›æŸå¤±ï¼ˆå¦‚`Loss_contrast`ï¼‰æ–¹å·®ç‰¹åˆ«å¤§

**è§£å†³ï¼š** å¯¹è¿™äº›æŸå¤±ä½¿ç”¨æ›´ä½çš„è®°å½•é¢‘ç‡

```python
# é«˜æ–¹å·®æŸå¤±ï¼šé™ä½è®°å½•é¢‘ç‡
high_variance_losses = ['contrast', 'pose_consistency']

if writer is not None:
    global_step = epoch * len(dataloader) + batch_idx
    
    # æ™®é€šæŸå¤±ï¼šæ­£å¸¸è®°å½•
    writer.add_scalar('Train/Loss', loss.item(), global_step)
    
    # é«˜æ–¹å·®æŸå¤±ï¼šé™ä½è®°å½•é¢‘ç‡
    for key, value in losses.items():
        if isinstance(value, torch.Tensor):
            if any(hv in key.lower() for hv in high_variance_losses):
                # æ¯50ä¸ªbatchè®°å½•ä¸€æ¬¡
                if batch_idx % 50 == 0 or batch_idx == len(dataloader) - 1:
                    writer.add_scalar(f'Train/Loss_{key}', value.item(), global_step)
            else:
                # æ¯10ä¸ªbatchè®°å½•ä¸€æ¬¡
                if batch_idx % 10 == 0 or batch_idx == len(dataloader) - 1:
                    writer.add_scalar(f'Train/Loss_{key}', value.item(), global_step)
```

---

### æ–¹æ¡ˆ5ï¼šä½¿ç”¨epochçº§åˆ«çš„è®°å½•ï¼ˆæœ€ç®€å•ï¼‰

**é—®é¢˜ï¼š** batchçº§åˆ«çš„è®°å½•å¤ªå¯†é›†

**è§£å†³ï¼š** åªåœ¨epochç»“æŸæ—¶è®°å½•å¹³å‡æŸå¤±

```python
# åœ¨ train_epoch å‡½æ•°ä¸­ï¼Œç§»é™¤batchçº§åˆ«çš„è®°å½•
# åªåœ¨å‡½æ•°ç»“æŸæ—¶è®°å½•å¹³å‡æŸå¤±

# è®¡ç®—å¹³å‡æŸå¤±
avg_loss = total_loss / num_batches if num_batches > 0 else 0.0
for key in loss_components:
    loss_components[key] = loss_components[key] / num_batches if num_batches > 0 else 0.0

# è®°å½•åˆ°TensorBoardï¼ˆepochçº§åˆ«ï¼‰
if writer is not None:
    writer.add_scalar('Train/AvgLoss', avg_loss, epoch)
    for key, value in loss_components.items():
        writer.add_scalar(f'Train/Loss_{key}', value, epoch)
```

**æ³¨æ„ï¼š** è¿™æ ·ä¼šå¤±å»batchçº§åˆ«çš„ç»†èŠ‚ï¼Œä½†æ›²çº¿ä¼šæ›´å¹³æ»‘

---

## ğŸ”§ æ¨èå®æ–½æ–¹æ¡ˆ

### æœ€ä½³æ–¹æ¡ˆï¼šç»„åˆæ–¹æ¡ˆ1å’Œæ–¹æ¡ˆ4

```python
# åœ¨ train_universal.py çš„ train_epoch å‡½æ•°ä¸­

# è®°å½•åˆ°TensorBoard
if writer is not None:
    global_step = epoch * len(dataloader) + batch_idx
    
    # é«˜æ–¹å·®æŸå¤±ï¼šé™ä½è®°å½•é¢‘ç‡
    high_variance_losses = ['contrast', 'pose_consistency']
    
    # æ™®é€šæŸå¤±ï¼šæ¯10ä¸ªbatchè®°å½•ä¸€æ¬¡
    if batch_idx % 10 == 0 or batch_idx == len(dataloader) - 1:
        writer.add_scalar('Train/Loss', loss.item(), global_step)
        
        for key, value in losses.items():
            if isinstance(value, torch.Tensor):
                # é«˜æ–¹å·®æŸå¤±ï¼šæ¯50ä¸ªbatchè®°å½•ä¸€æ¬¡
                if any(hv in key.lower() for hv in high_variance_losses):
                    if batch_idx % 50 == 0 or batch_idx == len(dataloader) - 1:
                        writer.add_scalar(f'Train/Loss_{key}', value.item(), global_step)
                else:
                    writer.add_scalar(f'Train/Loss_{key}', value.item(), global_step)
```

---

## ğŸ“Š ä¸ºä»€ä¹ˆä¼šå‡ºç°"æ—¶é—´å€’æµ"ï¼Ÿ

### æŠ€æœ¯åŸå› 

1. **EMAçš„æ»åæ€§**ï¼š
   - å¹³æ»‘å€¼æ€»æ˜¯åŸºäº**å½“å‰å’Œè¿‡å»**çš„æ•°æ®
   - å½“åŸå§‹æ•°æ®å¿«é€Ÿå˜åŒ–æ—¶ï¼Œå¹³æ»‘å€¼"è¿½èµ¶"åŸå§‹å€¼
   - è§†è§‰ä¸Šçœ‹èµ·æ¥åƒæ˜¯"å€’æµ"

2. **æ•°æ®ç‚¹è¿æ¥æ–¹å¼**ï¼š
   - TensorBoardæŒ‰æ¥æ”¶é¡ºåºè¿æ¥æ•°æ®ç‚¹
   - å¦‚æœæ•°æ®ç‚¹æ³¢åŠ¨å¤§ï¼Œçº¿æ¡ä¼šäº¤å‰
   - é«˜å¯†åº¦æ•°æ®ç‚¹äº§ç”Ÿé‡å æ•ˆæœ

3. **å¹³æ»‘çª—å£æ•ˆåº”**ï¼š
   - å¹³æ»‘ç®—æ³•è€ƒè™‘å¤šä¸ªå†å²ç‚¹
   - ç»˜åˆ¶æ—¶å¯èƒ½æ˜¾ç¤ºè¿™äº›å†å²ç‚¹çš„èŒƒå›´
   - äº§ç”Ÿ"å‘åå»¶ä¼¸"çš„è§†è§‰æ•ˆæœ

### è§†è§‰é”™è§‰

**ä¸æ˜¯çœŸæ­£çš„"æ—¶é—´å€’æµ"**ï¼Œè€Œæ˜¯ï¼š
- å¹³æ»‘ç®—æ³•çš„æ»åæ•ˆåº”
- é«˜æ–¹å·®æ•°æ®çš„å¯†é›†ç»˜åˆ¶
- å¤šæ¡çº¿çš„é‡å æ•ˆæœ

---

## ğŸ¯ éªŒè¯æ–¹æ³•

### æ£€æŸ¥global_stepæ˜¯å¦å•è°ƒé€’å¢

```python
# åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ éªŒè¯
if writer is not None:
    global_step = epoch * len(dataloader) + batch_idx
    
    # éªŒè¯ï¼šç¡®ä¿global_stepå•è°ƒé€’å¢
    if not hasattr(train_epoch, 'last_step'):
        train_epoch.last_step = -1
    
    if global_step <= train_epoch.last_step:
        print(f"è­¦å‘Šï¼šglobal_stepä¸å•è°ƒï¼å½“å‰={global_step}, ä¸Šæ¬¡={train_epoch.last_step}")
    
    train_epoch.last_step = global_step
    
    writer.add_scalar('Train/Loss', loss.item(), global_step)
```

---

## ğŸ’¡ æ€»ç»“

**"æ—¶é—´å€’æµ"å›¾çš„äº§ç”ŸåŸå› ï¼š**

1. âœ… **TensorBoardçš„EMAå¹³æ»‘ç®—æ³•** - å¯¼è‡´æ»åè§†è§‰æ•ˆæœ
2. âœ… **åŸå§‹æ•°æ®çš„é«˜æ–¹å·®** - äº§ç”Ÿå¤§é‡äº¤å‰çº¿æ¡
3. âœ… **æ•°æ®ç‚¹è¿‡äºå¯†é›†** - æ¯ä¸ªbatchéƒ½è®°å½•
4. âœ… **å¹³æ»‘çª—å£çš„æ˜¾ç¤º** - æ˜¾ç¤ºå†å²æ•°æ®èŒƒå›´

**è§£å†³æ–¹æ¡ˆï¼š**

1. âœ… **é™ä½è®°å½•é¢‘ç‡** - æ¯Nä¸ªbatchè®°å½•ä¸€æ¬¡
2. âœ… **åˆ†ç¦»é«˜æ–¹å·®æŸå¤±** - å¯¹é«˜æ–¹å·®æŸå¤±ä½¿ç”¨æ›´ä½é¢‘ç‡
3. âœ… **è°ƒæ•´TensorBoardå¹³æ»‘åº¦** - åœ¨ç•Œé¢ä¸­è°ƒæ•´
4. âœ… **ä½¿ç”¨epochçº§åˆ«è®°å½•** - æœ€ç®€å•ä½†å¤±å»ç»†èŠ‚

**æ¨èï¼š** ä½¿ç”¨æ–¹æ¡ˆ1+æ–¹æ¡ˆ4çš„ç»„åˆï¼Œæ—¢èƒ½ä¿æŒè¶‹åŠ¿æ¸…æ™°ï¼Œåˆèƒ½å‡å°‘è§†è§‰æ··ä¹±ã€‚
