# 24GB显卡优化说明

## 概述

代码已针对24GB显卡进行优化，充分利用显存资源，提升训练速度和效率。

## 主要优化

### 1. 默认配置调整

- **batch_size**: 从32增加到**128**（24GB显卡推荐）
- **混合精度训练（FP16）**: 默认启用，节省约50%显存并加速训练
- **梯度累积**: 支持通过`--gradient_accumulation_steps`模拟更大的batch_size
- **数据加载优化**: 
  - `num_workers=4`（GPU时使用多进程加载）
  - `pin_memory=True`（加速数据传输到GPU）
  - `persistent_workers=True`（保持worker进程，减少开销）

### 2. 自动显存适配

代码会自动检测GPU显存大小并调整配置：

- **≥20GB**（如24GB）: 使用默认batch_size=128
- **10-20GB**: 自动调整为batch_size=64
- **<10GB**: 自动调整为batch_size=32

### 3. 混合精度训练（FP16）

默认启用混合精度训练，带来以下优势：

- **显存节省**: 约50%的显存节省
- **训练加速**: 在支持的GPU上可提升1.5-2倍速度
- **精度保持**: 对大多数任务精度影响很小

如需禁用，使用 `--no_amp` 参数。

### 4. 梯度累积

支持梯度累积来模拟更大的batch_size：

```bash
# 有效batch_size = batch_size × gradient_accumulation_steps
# 例如：batch_size=64, gradient_accumulation_steps=2 → 有效batch_size=128
python train_transformer/train.py \
    --batch_size 64 \
    --gradient_accumulation_steps 2
```

## 使用示例

### 基础训练（24GB显卡推荐配置）

```bash
python train_transformer/train.py \
    --features_224_dir /root/face000/features_224 \
    --video_dir /root/face000/train/datas/video \
    --face_dir /root/face000/train/datas/face \
    --batch_size 128 \
    --memory_fraction 0.9 \
    --allow_tf32
```

### 显存受限时使用梯度累积

```bash
# 如果batch_size=128导致OOM，可以使用梯度累积
python train_transformer/train.py \
    --batch_size 64 \
    --gradient_accumulation_steps 2 \
    --memory_fraction 0.9
```

### 禁用混合精度（如果需要更高精度）

```bash
python train_transformer/train.py \
    --batch_size 128 \
    --no_amp \
    --memory_fraction 0.9
```

### 最大化显存使用

```bash
# 使用90%显存（留10%给系统）
python train_transformer/train.py \
    --batch_size 128 \
    --memory_fraction 0.9 \
    --allow_tf32
```

## 显存使用估算

对于24GB显卡，典型配置下的显存使用：

| 配置 | batch_size | FP16 | 显存使用 | 说明 |
|------|-----------|------|---------|------|
| 推荐 | 128 | 是 | ~18-20GB | 平衡速度和显存 |
| 保守 | 64 | 是 | ~10-12GB | 留更多显存余量 |
| 激进 | 256 | 是 | ~22-24GB | 接近显存上限 |
| 无FP16 | 64 | 否 | ~18-20GB | 不使用混合精度 |

## 性能优化建议

### 1. 数据加载优化

- 使用SSD存储训练数据（减少I/O瓶颈）
- 确保`num_workers`设置合理（通常为CPU核心数的1/4到1/2）
- 使用`pin_memory=True`加速数据传输

### 2. 模型优化

- 使用轻量级模型（`--model_type lightweight_transformer`）
- 减少模型层数（`--num_layers 2`）
- 使用较小的隐藏维度（`--d_model 768`）

### 3. 训练策略

- 使用学习率调度器（`--use_scheduler`）
- 启用TF32加速（`--allow_tf32`，默认已启用）
- 使用梯度裁剪（已内置，max_norm=1.0）

## 监控显存使用

### 使用nvidia-smi监控

```bash
# 实时监控显存使用
watch -n 1 nvidia-smi
```

### 在代码中查看

训练开始时会显示：
```
检测到GPU显存: 24.0 GB
✓ 24GB显卡优化: batch_size=128, 梯度累积=1, 有效batch_size=128
✓ 已启用混合精度训练（FP16）
  这将节省约50%的显存并加速训练
```

## 常见问题

### Q1: 仍然出现OOM（显存不足）

**解决方案**：
1. 减小batch_size：`--batch_size 64` 或 `--batch_size 32`
2. 使用梯度累积：`--gradient_accumulation_steps 2`
3. 确保启用FP16（默认已启用）
4. 限制显存使用：`--memory_fraction 0.8`

### Q2: 训练速度慢

**解决方案**：
1. 确保启用FP16（默认已启用）
2. 启用TF32：`--allow_tf32`（默认已启用）
3. 增加batch_size（如果显存允许）
4. 使用更快的存储（SSD）
5. 检查数据加载是否成为瓶颈（增加`num_workers`）

### Q3: 如何知道当前配置是否适合24GB显卡？

**检查方法**：
1. 运行训练并观察显存使用
2. 如果显存使用<20GB，可以尝试增加batch_size
3. 如果接近24GB，保持当前配置或稍微减小
4. 如果出现OOM，减小batch_size或使用梯度累积

## 技术细节

### 混合精度训练实现

使用PyTorch的`torch.cuda.amp`：

```python
scaler = torch.cuda.amp.GradScaler()
with torch.cuda.amp.autocast():
    # 前向传播
    output = model(input)
    loss = criterion(output, target)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

### 梯度累积实现

```python
loss = loss / gradient_accumulation_steps
loss.backward()

if (batch_idx + 1) % gradient_accumulation_steps == 0:
    optimizer.step()
    optimizer.zero_grad()
```

### 数据加载优化

- `pin_memory=True`: 将数据固定在CPU内存中，加速传输到GPU
- `non_blocking=True`: 异步传输数据，不阻塞计算
- `persistent_workers=True`: 保持worker进程，减少进程创建开销

## 总结

24GB显卡优化配置：

✅ **默认batch_size=128**（充分利用显存）  
✅ **默认启用FP16**（节省显存并加速）  
✅ **自动显存适配**（根据GPU显存自动调整）  
✅ **数据加载优化**（多进程、pin_memory）  
✅ **梯度累积支持**（模拟更大batch_size）  

这些优化确保代码能够在24GB显卡上高效运行，充分利用硬件资源。

